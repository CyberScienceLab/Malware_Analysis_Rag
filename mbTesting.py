import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import re
import fitz  # PyMuPDF
import json 
import os
import gc
import numpy as np
import pandas as pd
import re
import requests
from transformers.utils import logging
logging.set_verbosity_error()


# Extract text from the PDF
def extract_text_from_pdf(pdf_name):
    pdf_name = "files/" + pdf_name
    pdf_document = fitz.open(pdf_name)
    all_text = ""
    for page_num in range(len(pdf_document)):
        page = pdf_document.load_page(page_num)
        text = page.get_text("text")
        all_text += text
    return all_text

def extract_sha256_hashes(text):
    # Define the regular expression pattern for a SHA-256 hash
    pattern = r'\b[a-fA-F0-9]{64}\b'
    
    # Find all matches in the input text
    hashes = re.findall(pattern, text)
    
    # Use a set to remove duplicates
    unique_hashes = set(hashes)
    
    return list(unique_hashes)

# Example usage
#text = "Here are some hashes: e7ccc45b46412eaa8ab40a9c2b9a747f01233f95975b573c9cb0b74c84350f18 and another one e7ccc45b46412eaa8ab40a9c2b9a747f01233f95975b573c9cb0b74c84350f18."

#hashes = extract_sha256_hashes(text)
#print(hashes)

# Function to make the request and save the response as a JSON file
def fetch_json(hash_number, output_dir):
    hash_number = hash_number.strip().replace('"', '')  # Clean the hash number
    
    # Replace 'your_api_key_here' with your actual Malware Bazaar API key
    api_key = 'bd01da3d343c4818664bd7dc04716e11'
    headers = {
        'API-KEY': api_key
    }

    url = 'https://mb-api.abuse.ch/api/v1/'

    # Define the payload for querying a specific hash
    payload = {
        'query': 'get_info',
        'hash': hash_number
    }

    try:
        # Make the request
        response = requests.post(url, headers=headers, data=payload, timeout=15)
        
        # Raise an exception if the request was unsuccessful
        response.raise_for_status()
        
        # Parse the JSON response
        data = response.json()
        
        # Create the output directory if it does not exist
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # Define the path to save the JSON file
        file_path = os.path.join(output_dir, f"{hash_number}.json")
        
        # Save the JSON response to a file
        with open(file_path, 'w') as json_file:
            json.dump(data, json_file, indent=4)
        
        print(f"Response saved to {file_path}")
    except requests.exceptions.HTTPError as http_err:
        print(f"HTTP error occurred for hash {hash_number}: {http_err}")
    except requests.exceptions.Timeout:
        print(f"The request timed out for hash {hash_number}")
    except requests.exceptions.RequestException as err:
        print(f"Other error occurred for hash {hash_number}: {err}")





userPDFName = input("Please Enter the name of the pdf that you would like to analyze (please include the .pdf at the end as well).")
all_text = extract_text_from_pdf(userPDFName)

#print(all_text)







def processJson(file_path):

    texts = []
    metadata = []
    #file_path = "mbjson"

    if file_path.endswith('.json'):
        with open(file_path, "r") as file:
                data = json.load(file)

            
        # Extract texts and metadata from the JSON data
        for item in data.get("data", []):
            sha256_hash = item.get("sha256_hash", "")
            vendor_intel = item.get("vendor_intel", {})
            vxCube = vendor_intel.get("vxCube", {})
            behaviour_list = vxCube.get("behaviour", [])
    
            # Extract each description in behaviour and append to texts
            textStr = ""
            for behaviour in behaviour_list:
                description = behaviour.get("rule", "")
                threat_level = behaviour.get("threat_level", "")
                    
                textStr += " behaviour description: " + description
                textStr += " threat level: " + threat_level

            texts.append(textStr)
    
            metadata.append({
                'sha256_hash': item.get('sha256_hash', ''),
                'sha3_384_hash': item.get('sha3_384_hash', ''),
                'sha1_hash': item.get('sha1_hash', ''),
                'md5_hash': item.get('md5_hash', ''),
                'first_seen': item.get('first_seen', ''),
                'last_seen': item.get('last_seen', ''),
                'file_name': item.get('file_name', ''),
                'file_size': item.get('file_size', ''),
                'file_type_mime': item.get('file_type_mime', ''),
                'file_type': item.get('file_type', ''),
                'reporter': item.get('reporter', ''),
                'origin_country': item.get('origin_country', ''),
                'anonymous': item.get('anonymous', ''),
                'signature': item.get('signature', ''),
                'imphash': item.get('imphash', ''),
                'tlsh': item.get('tlsh', ''),
                'telfhash': item.get('telfhash', ''),
                'gimphash': item.get('gimphash', ''),
                'ssdeep': item.get('ssdeep', ''),
                'dhash_icon': item.get('dhash_icon', ''),
                'comment': item.get('comment', ''),
                    'archive_pw': item.get('archive_pw', ''),
                    'delivery_method': item.get('delivery_method', ''),
                    'intelligence': json.dumps(item.get('intelligence', {})),  # Convert dict to JSON string
                    'file_information': json.dumps(item.get('file_information', [])),  # Convert list to JSON string
                    'ole_information': json.dumps(item.get('ole_information', [])),  # Convert list to JSON string
                    'yara_rules': json.dumps(item.get('yara_rules', [])),  # Convert list to JSON string
                    'vendor_intel': json.dumps(item.get('vendor_intel', {})),  # Convert dict to JSON string
                    'comments': json.dumps(item.get('comments', []))  # Convert list to JSON string
                })

        ##print("MARK ::")
        #print(texts)
        #print(metadata)

    return texts, metadata


def getJsonData(file_path):
    # Initialize empty strings for combined text and metadata
    all_texts = ""
    all_metadata = ""

    if file_path.endswith('.json'):
        with open(file_path, "r") as file:
            data = json.load(file)

        # Extract texts and metadata from the JSON data
        for item in data.get("data", []):
            sha256_hash = item.get("sha256_hash", "")
            vendor_intel = item.get("vendor_intel", {})
            vxCube = vendor_intel.get("vxCube", {})
            behaviour_list = vxCube.get("behaviour", [])

            # Extract each description in behaviour and append to textStr
            textStr = ""
            for behaviour in behaviour_list:
                description = behaviour.get("rule", "")
                threat_level = behaviour.get("threat_level", "")
                    
                textStr += " Behaviour description: " + description
                textStr += " Threat level: " + threat_level

            # Combine metadata into a single string
            metadata_str = (
                f"SHA256 Hash: {item.get('sha256_hash', '')}, "
                f"SHA3-384 Hash: {item.get('sha3_384_hash', '')}, "
                f"SHA1 Hash: {item.get('sha1_hash', '')}, "
                f"MD5 Hash: {item.get('md5_hash', '')}, "
                f"First Seen: {item.get('first_seen', '')}, "
                f"Last Seen: {item.get('last_seen', '')}, "
                f"File Name: {item.get('file_name', '')}, "
                f"File Size: {item.get('file_size', '')}, "
                f"File Type MIME: {item.get('file_type_mime', '')}, "
                f"File Type: {item.get('file_type', '')}, "
                f"Reporter: {item.get('reporter', '')}, "
                f"Origin Country: {item.get('origin_country', '')}, "
                f"Anonymous: {item.get('anonymous', '')}, "
                f"Signature: {item.get('signature', '')}, "
                f"IMPHASH: {item.get('imphash', '')}, "
                f"TLSH: {item.get('tlsh', '')}, "
                f"TELFHASH: {item.get('telfhash', '')}, "
                f"GIMPHASH: {item.get('gimphash', '')}, "
                f"SSDEEP: {item.get('ssdeep', '')}, "
                f"DHash Icon: {item.get('dhash_icon', '')}, "
                f"Comment: {item.get('comment', '')}, "
                f"Archive PW: {item.get('archive_pw', '')}, "
                f"Delivery Method: {item.get('delivery_method', '')}, "
                f"Intelligence: {json.dumps(item.get('intelligence', {}))}, "
                f"File Information: {json.dumps(item.get('file_information', []))}, "
                f"OLE Information: {json.dumps(item.get('ole_information', []))}, "
                f"YARA Rules: {json.dumps(item.get('yara_rules', []))}, "
                f"Vendor Intel: {json.dumps(item.get('vendor_intel', {}))}, "
                f"Comments: {json.dumps(item.get('comments', []))}"
            )

            # Append to the large strings
            all_texts += textStr + "\n\n"  # Separate entries by new lines
            all_metadata += metadata_str + "\n\n"  # Separate entries by new lines

    return all_texts, all_metadata

import json

import json

def getJsonDataEmbed(file_path):
    # Initialize empty strings for combined text and metadata
    all_texts = ""
    all_metadata = ""

    if file_path.endswith('.json'):
        with open(file_path, "r") as file:
            data = json.load(file)

        # Extract texts and metadata from the JSON data
        for item in data.get("data", []):
            sha256_hash = item.get("sha256_hash", "")
            vendor_intel = item.get("vendor_intel", {})
            vxCube = vendor_intel.get("vxCube", {})
            behaviour_list = vxCube.get("behaviour", [])
            yara_rules = item.get("yara_rules", [])
            triage = vendor_intel.get("Triage", {})

            # Extract each description in behaviour and append to textStr
            textStr = ""
            for behaviour in behaviour_list:
                description = behaviour.get("rule", "")
                #threat_level = behaviour.get("threat_level", "")
                
                textStr += " Behaviour description: " + description
                #textStr += " Threat level: " + threat_level
                textStr += "\n"  # Separate entries for better readability

            # Append YARA rules descriptions
            for yara_rule in yara_rules:
                rule_name = yara_rule.get("rule_name", "")
                author = yara_rule.get("author", "")
                description = yara_rule.get("description", "")
                
                if rule_name:
                    textStr += f" YARA Rule Name: {rule_name}"
                #if author:
                    #textStr += f" Author: {author}"
                #if description:
                    #textStr += f" Description: {description}"
                textStr += "\n"  # Separate entries for better readability

            # Append signatures from Triage
            signatures = triage.get("signatures", [])
            for signature in signatures:
                signature_text = signature.get("signature", "")
                #score = signature.get("score", "")
                
                if signature_text:
                    textStr += f" Signature: {signature_text}"
                #if score:
                    #textStr += f" Score: {score}"
                textStr += "\n"  # Separate entries for better readability

            # Combine metadata into a single string
            metadata_str = (
                f"SHA256 Hash: {item.get('sha256_hash', '')}, "
                f"SHA3-384 Hash: {item.get('sha3_384_hash', '')}, "
                f"SHA1 Hash: {item.get('sha1_hash', '')}, "
                f"MD5 Hash: {item.get('md5_hash', '')}, "
                f"First Seen: {item.get('first_seen', '')}, "
                f"Last Seen: {item.get('last_seen', '')}, "
                f"File Name: {item.get('file_name', '')}, "
                f"File Size: {item.get('file_size', '')}, "
                f"File Type MIME: {item.get('file_type_mime', '')}, "
                f"File Type: {item.get('file_type', '')}, "
                f"Reporter: {item.get('reporter', '')}, "
                f"Origin Country: {item.get('origin_country', '')}, "
                #f"Anonymous: {item.get('anonymous', '')}, "
                #f"Signature: {item.get('signature', '')}, "
                f"IMPHASH: {item.get('imphash', '')}, "
                f"TLSH: {item.get('tlsh', '')}, "
                #f"TELFHASH: {item.get('telfhash', '')}, "
                #f"GIMPHASH: {item.get('gimphash', '')}, "
                #f"SSDEEP: {item.get('ssdeep', '')}, "
                #f"DHash Icon: {item.get('dhash_icon', '')}, "
                #f"Comment: {item.get('comment', '')}, "
                #f"Archive PW: {item.get('archive_pw', '')}, "
                f"Delivery Method: {item.get('delivery_method', '')}, "
                f"Intelligence: {json.dumps(item.get('intelligence', {}))}, "
                f"File Information: {json.dumps(item.get('file_information', []))}, "
                #f"OLE Information: {json.dumps(item.get('ole_information', []))}, "
                #f"YARA Rules: {json.dumps(item.get('yara_rules', []))}, "
                f"Vendor Intel: {json.dumps(item.get('vendor_intel', {}))}, "
                #f"Comments: {json.dumps(item.get('comments', []))}"
            )

            # Append to the large strings
            all_texts += textStr + "\n\n"  # Separate entries by new lines
            all_metadata += metadata_str + "\n\n"  # Separate entries by new lines

    return all_texts, all_metadata

import json

def getJsonDataEmbed2(file_path):
    # Initialize empty lists for combined text and metadata
    all_texts = []
    all_metadata = []

    if file_path.endswith('.json'):
        with open(file_path, "r") as file:
            data = json.load(file)

        # Extract texts and metadata from the JSON data
        for item in data.get("data", []):
            sha256_hash = item.get("sha256_hash", "")
            vendor_intel = item.get("vendor_intel", {})
            vxCube = vendor_intel.get("vxCube", {})
            behaviour_list = vxCube.get("behaviour", [])
            yara_rules = item.get("yara_rules", [])
            triage = vendor_intel.get("Triage", {})

            # Build the text for the current item
            text_parts = []

            # Extract each description in behaviour and append to text_parts
            for behaviour in behaviour_list:
                description = behaviour.get("rule", "")
                text_parts.append(f"Behaviour description: {description}")

            # Append YARA rules descriptions
            for yara_rule in yara_rules:
                rule_name = yara_rule.get("rule_name", "")
                text_parts.append(f"YARA Rule Name: {rule_name}")

            # Append signatures from Triage
            signatures = triage.get("signatures", [])
            for signature in signatures:
                signature_text = signature.get("signature", "")
                text_parts.append(f"Signature: {signature_text}")

            # Join all text parts for this item
            textStr = "\n".join(text_parts)
            
            # Build metadata for the current item
            metadata_parts = [
                f"SHA256 Hash: {item.get('sha256_hash', '')}",
                f"SHA3-384 Hash: {item.get('sha3_384_hash', '')}",
                f"SHA1 Hash: {item.get('sha1_hash', '')}",
                f"MD5 Hash: {item.get('md5_hash', '')}",
                f"First Seen: {item.get('first_seen', '')}",
                f"Last Seen: {item.get('last_seen', '')}",
                f"File Name: {item.get('file_name', '')}",
                f"File Size: {item.get('file_size', '')}",
                f"File Type MIME: {item.get('file_type_mime', '')}",
                f"File Type: {item.get('file_type', '')}",
                f"Reporter: {item.get('reporter', '')}",
                f"Origin Country: {item.get('origin_country', '')}",
                f"IMPHASH: {item.get('imphash', '')}",
                f"TLSH: {item.get('tlsh', '')}",
                f"Delivery Method: {item.get('delivery_method', '')}",
                f"Intelligence: {json.dumps(item.get('intelligence', {}))}",
                f"File Information: {json.dumps(item.get('file_information', []))}",
                f"Vendor Intel: {json.dumps(item.get('vendor_intel', {}))}"
            ]
            
            # Join all metadata parts for this item
            metadata_str = "\n".join(metadata_parts)

            # Append to the lists
            all_texts.append(textStr)
            all_metadata.append(metadata_str)

    # Join all texts and metadata into single strings
    all_texts_str = "\n\n".join(all_texts)
    all_metadata_str = "\n\n".join(all_metadata)

    return all_texts_str, all_metadata_str



# Initialize the model once
def initialize_model():
    model_id = "meta-llama/Meta-Llama-3-8B-Instruct"
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(
        model_id,
        torch_dtype=torch.bfloat16,
        device_map="auto",
    )
    return tokenizer, model

def cleanup_model(model):
    del model
    torch.cuda.empty_cache()
    gc.collect()



hashes = extract_sha256_hashes(all_text)
print(hashes)


tokenizer, model = initialize_model()



for hash in hashes:
    fetch_json(hash, "files/mbJson")
    text, metadata = getJsonDataEmbed(f"files/mbJson/{hash}.json")
    #print(text)
    print("The text is:" + text)
    print("\n\n\n")
    print("The metadata is:" + metadata)
    print("\n\n\n")
    messages = [

    
       

        {"role": "system", "content": f"""You are a chatbot that verifies the correct use of malware hash numbers mentioned in a Threat Intelligence Report. A hash number is used correctly when it closely matches the provided Correct hash number description. Incorrect usage includes accoaiting a different malware sample, misrepresenting the Correct hash number information, or inaccurately applying the hash number given the correct infromation.
                            Correct Hash Number Information:
                            Correct Brieif Description:{text}. Correct Hash Metadata: {metadata}. 
                            Instructions:
                            1. Verify each Hash Number mentioned in the user-provided report.
                            2. Indicate whether each Hash is used correctly or not.
                            3. You must provide a detailed explanation with direct quotes from both the report and the correct Hash Number Description.
                            A Hash Number in the report is incorrect if it describes a different malware sample, even if the report accurately describes the malware and its impact, and provides mitigation recommendations.
                            
                            Example Output:
                            
                            Analysis Summary:

                            Status: Hash Mismatch Detected

                            Provided Hash: 9d948a18acdd4d4ea3c1fbab2ea72de766e1434b208ed78ce000b81ece996111

                            Correct Hash: e7ccc45b46412eaa8ab40a9c2b9a747f01233f95975b573c9cb0b74c84350222

                            Issue Description: The threat intelligence report mistakenly associates the provided hash with malware that scans keyboard inputs. However, the correct hash corresponds to a different sample with functionality related to scanning and recording microphone inputs.

                            Provided Hash Details:

                            File Name: example_keyboard_key_logger.exe
                            File Size: 678,400 bytes
                            File Type: Executable (exe)
                            First Seen: August 6, 2024
                            Functionality: Scans and logs keystrokes
                            Signature: KeyLogger
                            Origin Country: Hungary
                            Analysis Link: Keyboard Key Logger Analysis

                            Correct Hash Details:

                            File Name: example_microphone_spyware.exe
                            File Size: 678,400 bytes
                            File Type: Executable (exe)
                            First Seen: August 6, 2024
                            Functionality: Monitors and records microphone inputs
                            Signature: MicrophoneSpy
                            Origin Country: Hungary
                            Analysis Link: Microphone Spyware Analysis"""},
        {"role": "user", "content": f"Please verify if the following hash Number: {hash}; have been used correctly in the following Threat Intelligence Report: {all_text}."}
    ]
    

    input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors="pt").to(model.device)
    outputs = model.generate(input_ids, max_new_tokens=700, eos_token_id=tokenizer.eos_token_id, do_sample=True, temperature=0.3, top_p=0.9)
    response = outputs[0][input_ids.shape[-1]:]
    llm_output = tokenizer.decode(response, skip_special_tokens=True)
    
    print(llm_output)

    import os

    # Path to the file you want to delete
    file_path = f'files/mbJson/{hash}.json'

    # Check if the file exists before trying to delete it
    if os.path.isfile(file_path):
        #os.remove(file_path)
        print(f"{file_path} has been deleted.")
    else:
        print(f"{file_path} does not exist.")



    