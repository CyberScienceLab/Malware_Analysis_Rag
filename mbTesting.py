import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import re
import fitz  # PyMuPDF
import json 
import os
import gc
import numpy as np
import pandas as pd
import re
import requests
from transformers.utils import logging
logging.set_verbosity_error()


# Extract text from the PDF
def extract_text_from_pdf(pdf_name):
    pdf_document = fitz.open(pdf_name)
    all_text = ""
    for page_num in range(len(pdf_document)):
        page = pdf_document.load_page(page_num)
        text = page.get_text("text")
        all_text += text
    return all_text

def extract_sha256_hashes(text):
    # Define the regular expression pattern for a SHA-256 hash
    pattern = r'\b[a-fA-F0-9]{64}\b'
    
    # Find all matches in the input text
    hashes = re.findall(pattern, text)
    
    # Use a set to remove duplicates
    unique_hashes = set(hashes)
    
    return list(unique_hashes)

# Example usage
#text = "Here are some hashes: e7ccc45b46412eaa8ab40a9c2b9a747f01233f95975b573c9cb0b74c84350f18 and another one e7ccc45b46412eaa8ab40a9c2b9a747f01233f95975b573c9cb0b74c84350f18."

#hashes = extract_sha256_hashes(text)
#print(hashes)

# Function to make the request and save the response as a JSON file
def fetch_json(hash_number, output_dir):
    hash_number = hash_number.strip().replace('"', '')  # Clean the hash number
    
    # Replace 'your_api_key_here' with your actual Malware Bazaar API key
    api_key = 'bd01da3d343c4818664bd7dc04716e11'
    headers = {
        'API-KEY': api_key
    }

    url = 'https://mb-api.abuse.ch/api/v1/'

    # Define the payload for querying a specific hash
    payload = {
        'query': 'get_info',
        'hash': hash_number
    }

    try:
        # Make the request
        response = requests.post(url, headers=headers, data=payload, timeout=15)
        
        # Raise an exception if the request was unsuccessful
        response.raise_for_status()
        
        # Parse the JSON response
        data = response.json()
        
        # Create the output directory if it does not exist
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # Define the path to save the JSON file
        file_path = os.path.join(output_dir, f"{hash_number}.json")
        
        # Save the JSON response to a file
        with open(file_path, 'w') as json_file:
            json.dump(data, json_file, indent=4)
        
        print(f"Response saved to {file_path}")
    except requests.exceptions.HTTPError as http_err:
        print(f"HTTP error occurred for hash {hash_number}: {http_err}")
    except requests.exceptions.Timeout:
        print(f"The request timed out for hash {hash_number}")
    except requests.exceptions.RequestException as err:
        print(f"Other error occurred for hash {hash_number}: {err}")





userPDFName = input("Please Enter the name of the pdf that you would like to analyze (please include the .pdf at the end as well).")
all_text = extract_text_from_pdf(userPDFName)

#print(all_text)







def getJsonData(file_path):

    texts = []
    metadata = []
    #file_path = "mbjson"

    if file_path.endswith('.json'):
        with open(file_path, "r") as file:
                data = json.load(file)

            
        # Extract texts and metadata from the JSON data
        for item in data.get("data", []):
            sha256_hash = item.get("sha256_hash", "")
            vendor_intel = item.get("vendor_intel", {})
            vxCube = vendor_intel.get("vxCube", {})
            behaviour_list = vxCube.get("behaviour", [])
    
            # Extract each description in behaviour and append to texts
            textStr = ""
            for behaviour in behaviour_list:
                description = behaviour.get("rule", "")
                threat_level = behaviour.get("threat_level", "")
                    
                textStr += " behaviour description: " + description
                textStr += " threat level: " + threat_level

            texts.append(textStr)
    
            metadata.append({
                'sha256_hash': item.get('sha256_hash', ''),
                'sha3_384_hash': item.get('sha3_384_hash', ''),
                'sha1_hash': item.get('sha1_hash', ''),
                'md5_hash': item.get('md5_hash', ''),
                'first_seen': item.get('first_seen', ''),
                'last_seen': item.get('last_seen', ''),
                'file_name': item.get('file_name', ''),
                'file_size': item.get('file_size', ''),
                'file_type_mime': item.get('file_type_mime', ''),
                'file_type': item.get('file_type', ''),
                'reporter': item.get('reporter', ''),
                'origin_country': item.get('origin_country', ''),
                'anonymous': item.get('anonymous', ''),
                'signature': item.get('signature', ''),
                'imphash': item.get('imphash', ''),
                'tlsh': item.get('tlsh', ''),
                'telfhash': item.get('telfhash', ''),
                'gimphash': item.get('gimphash', ''),
                'ssdeep': item.get('ssdeep', ''),
                'dhash_icon': item.get('dhash_icon', ''),
                'comment': item.get('comment', ''),
                    'archive_pw': item.get('archive_pw', ''),
                    'delivery_method': item.get('delivery_method', ''),
                    'intelligence': json.dumps(item.get('intelligence', {})),  # Convert dict to JSON string
                    'file_information': json.dumps(item.get('file_information', [])),  # Convert list to JSON string
                    'ole_information': json.dumps(item.get('ole_information', [])),  # Convert list to JSON string
                    'yara_rules': json.dumps(item.get('yara_rules', [])),  # Convert list to JSON string
                    'vendor_intel': json.dumps(item.get('vendor_intel', {})),  # Convert dict to JSON string
                    'comments': json.dumps(item.get('comments', []))  # Convert list to JSON string
                })

        ##print("MARK ::")
        #print(texts)
        print(metadata)

    return texts, metadata

# Initialize the model once
def initialize_model():
    model_id = "meta-llama/Meta-Llama-3-8B-Instruct"
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(
        model_id,
        torch_dtype=torch.bfloat16,
        device_map="auto",
    )
    return tokenizer, model

def cleanup_model(model):
    del model
    torch.cuda.empty_cache()
    gc.collect()



hashes = extract_sha256_hashes(all_text)
print(hashes)


tokenizer, model = initialize_model()



for hash in hashes:
    fetch_json(hash, "mbJson")
    text, metadata = getJsonData(f"mbJson/{hash}.json")
    #print(text)
    print(text)
    print("\n\n\n")
    print(metadata)
    print("\n\n\n")
    messages = [

    
       

        {"role": "system", "content": f"""You are a chatbot that verifies the correct use of malware hash numbers mentioned in a Threat Intelligence Report. A hash number is used correctly when it closely matches the provided Correct hash number description. Incorrect usage includes accoaiting a different malware sample, misrepresenting the Correct hash number information, or inaccurately applying the hash number given the correct infromation.
                            Correct Hash Number Information:
                            Correct Brieif Description:{text}. Correct Hash Metadata: {metadata}. 
                            Instructions:
                            1. Verify each Hash Number mentioned in the user-provided report.
                            2. Indicate whether each Hash is used correctly or not.
                            3. You must provide a detailed explanation with direct quotes from both the report and the correct Hash Number Description.
                            A Hash Number in the report is incorrect if it describes a different malware sample, even if the report accurately describes the malware and its impact, and provides mitigation recommendations.
                            
                            Example Output:
                            
                            Analysis Summary:

                            Status: Hash Mismatch Detected

                            Provided Hash: 9d948a18acdd4d4ea3c1fbab2ea72de766e1434b208ed78ce000b81ece996111

                            Correct Hash: e7ccc45b46412eaa8ab40a9c2b9a747f01233f95975b573c9cb0b74c84350222

                            Issue Description: The threat intelligence report mistakenly associates the provided hash with malware that scans keyboard inputs. However, the correct hash corresponds to a different sample with functionality related to scanning and recording microphone inputs.

                            Provided Hash Details:

                            File Name: example_keyboard_key_logger.exe
                            File Size: 678,400 bytes
                            File Type: Executable (exe)
                            First Seen: August 6, 2024
                            Functionality: Scans and logs keystrokes
                            Signature: KeyLogger
                            Origin Country: Hungary
                            Analysis Link: Keyboard Key Logger Analysis

                            Correct Hash Details:

                            File Name: example_microphone_spyware.exe
                            File Size: 678,400 bytes
                            File Type: Executable (exe)
                            First Seen: August 6, 2024
                            Functionality: Monitors and records microphone inputs
                            Signature: MicrophoneSpy
                            Origin Country: Hungary
                            Analysis Link: Microphone Spyware Analysis"""},
        {"role": "user", "content": f"Please verify if the following hash Number: {hash}; have been used correctly in the following Threat Intelligence Report: {all_text}."}
    ]
    

    input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors="pt").to(model.device)
    outputs = model.generate(input_ids, max_new_tokens=700, eos_token_id=tokenizer.eos_token_id, do_sample=True, temperature=0.3, top_p=0.9)
    response = outputs[0][input_ids.shape[-1]:]
    llm_output = tokenizer.decode(response, skip_special_tokens=True)
    
    print(llm_output)

    import os

    # Path to the file you want to delete
    file_path = f'mbJson/{hash}.json'

    # Check if the file exists before trying to delete it
    if os.path.isfile(file_path):
        os.remove(file_path)
        print(f"{file_path} has been deleted.")
    else:
        print(f"{file_path} does not exist.")



    


